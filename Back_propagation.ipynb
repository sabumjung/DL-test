{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back-propagation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabumjung/Pytorch/blob/master/Back_propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lf0yaAdkxfty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "b903d8e9-8bd1-4ad9-f1ec-ce3e47a7c418"
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m\u001b[0m",
            "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-eb42ca6e4af3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: No module named torch",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo install torch, click the button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zNnFIbFPxx_J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yuQ2PKBjxyXh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data\n",
        "import torch\n",
        "x_data=[1.0, 2.0, 3.0]\n",
        "y_data=[2.0, 4.0, 6.0]\n",
        "w=torch.tensor([1.0], requires_grad=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nL4E3ZHOz3Aq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# modeling\n",
        "def forward(x):\n",
        "  return x*w\n",
        "\n",
        "def loss(x,y):\n",
        "  y_pred=forward(x)\n",
        "  return (y_pred-y)*(y_pred-y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mibpoYTl0q6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 773
        },
        "outputId": "32013032-bcf7-4e24-ccab-a61581bd172c"
      },
      "cell_type": "code",
      "source": [
        "# training\n",
        "print(\"predict (before training)\", 4, forward(4))\n",
        "for epoch in range(10):\n",
        "  #x[i]와 y[i]가 짝을이루어 x_val, y_val로 대입된다.\n",
        "  for x_val, y_val in zip(x_data, y_data): #1\n",
        "    #x_val, y_val에 입력하여 loss를 계산하고 결과를 l에 넣어줌\n",
        "    l = loss(x_val, y_val) #2\n",
        "    #back propagation을 실행하여 dloss/dweight를 계산하고 w.grad.data에 넣는다.\n",
        "    l.backward() #3\n",
        "    print(\"grad: \", x_val, y_val,w.grad.data[0])\n",
        "    # w.data를 gradient에 작은수를 곱해서 빼준다.\n",
        "    w.data = w.data - 0.01 * w.grad.data #4\n",
        "    # 매번 backward가 실행될 때 gradient가 더해지는 구조이므로 zero-()를 해서 0으로 초기화\n",
        "    w.grad.data.zero_() #5\n",
        "  print(\"progress:\", epoch, l.data[0])\n",
        "  print(l.data[0])\n",
        "print(\"predict (after training)\" , 4, forward(4))\n",
        "#결과를 보면 epoch진행될수록 gradient값이 줄어들게됨을 알 수 있다.\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('predict (before training)', 4, tensor([4.], grad_fn=<MulBackward>))\n",
            "('grad: ', 1.0, 2.0, tensor(-2.))\n",
            "('grad: ', 2.0, 4.0, tensor(-7.8400))\n",
            "('grad: ', 3.0, 6.0, tensor(-16.2288))\n",
            "('progress:', 0, tensor(7.3159))\n",
            "('grad: ', 1.0, 2.0, tensor(-1.4786))\n",
            "('grad: ', 2.0, 4.0, tensor(-5.7962))\n",
            "('grad: ', 3.0, 6.0, tensor(-11.9981))\n",
            "('progress:', 1, tensor(3.9988))\n",
            "('grad: ', 1.0, 2.0, tensor(-1.0932))\n",
            "('grad: ', 2.0, 4.0, tensor(-4.2852))\n",
            "('grad: ', 3.0, 6.0, tensor(-8.8704))\n",
            "('progress:', 2, tensor(2.1857))\n",
            "('grad: ', 1.0, 2.0, tensor(-0.8082))\n",
            "('grad: ', 2.0, 4.0, tensor(-3.1681))\n",
            "('grad: ', 3.0, 6.0, tensor(-6.5580))\n",
            "('progress:', 3, tensor(1.1946))\n",
            "('grad: ', 1.0, 2.0, tensor(-0.5975))\n",
            "('grad: ', 2.0, 4.0, tensor(-2.3422))\n",
            "('grad: ', 3.0, 6.0, tensor(-4.8484))\n",
            "('progress:', 4, tensor(0.6530))\n",
            "('grad: ', 1.0, 2.0, tensor(-0.4417))\n",
            "('grad: ', 2.0, 4.0, tensor(-1.7316))\n",
            "('grad: ', 3.0, 6.0, tensor(-3.5845))\n",
            "('progress:', 5, tensor(0.3569))\n",
            "('grad: ', 1.0, 2.0, tensor(-0.3266))\n",
            "('grad: ', 2.0, 4.0, tensor(-1.2802))\n",
            "('grad: ', 3.0, 6.0, tensor(-2.6500))\n",
            "('progress:', 6, tensor(0.1951))\n",
            "('grad: ', 1.0, 2.0, tensor(-0.2414))\n",
            "('grad: ', 2.0, 4.0, tensor(-0.9465))\n",
            "('grad: ', 3.0, 6.0, tensor(-1.9592))\n",
            "('progress:', 7, tensor(0.1066))\n",
            "('grad: ', 1.0, 2.0, tensor(-0.1785))\n",
            "('grad: ', 2.0, 4.0, tensor(-0.6997))\n",
            "('grad: ', 3.0, 6.0, tensor(-1.4485))\n",
            "('progress:', 8, tensor(0.0583))\n",
            "('grad: ', 1.0, 2.0, tensor(-0.1320))\n",
            "('grad: ', 2.0, 4.0, tensor(-0.5173))\n",
            "('grad: ', 3.0, 6.0, tensor(-1.0709))\n",
            "('progress:', 9, tensor(0.0319))\n",
            "('predict (after training)', 4, tensor([7.8049], grad_fn=<MulBackward>))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y1tQ64du1EoS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}