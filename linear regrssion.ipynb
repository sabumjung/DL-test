{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled25.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabumjung/Pytorch/blob/master/linear%20regrssion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "nFPRU6Ae5vnf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "\n",
        "# 모델링은 design model -> construct loss/optimizer -> training\n",
        "\n",
        "x_data = torch.tensor([ [1.0],[2.0],[3.0] ])\n",
        "y_data = torch.tensor([ [2.0],[4.0],[6.0] ])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uS38tqle5yha",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MyModel(torch.nn.Module):#torch.nn.Module을 상속받음\n",
        "    #class 생성자 같은 느낌임. 처음 만들어질 때 초기화 해줌. 반드시 필요.\n",
        "    def __init__(self):\n",
        "        #부모 class로부터 상속받은 class는 처음 initialize 해줄 때 부모의 init을 해 주어야 한다.\n",
        "        super(MyModel,self).__init__()\n",
        "        self.linear = torch.nn.Linear(1,1) \n",
        "        # MyModel에 실질적인 연산을 할 모델을 구성하는 부분.\n",
        "        # 우리는 간단한 모델을 구성할 것이기 때문에 \n",
        "        # torch API에서 제공하는 torch.nn.Linear만 가지고 우리의 모델을 구성했다.\n",
        "        # input개수가 한개이고 output 개수도 한개인 Linear model을 만들어주게 된다.\n",
        "         \n",
        "    #forward 모델을 정의\n",
        "    #예측을 수행하는 함수. 모델을 만들 때 반드시 필요.\n",
        "    def forward(self,x):\n",
        "        y_pred = self.linear(x)\n",
        "        return y_pred\n",
        "     \n",
        "model = MyModel() #model이라는 변수에 만든 모델을 넣어준다.\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x5NagvjA5-qB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#PyTorch API 로부터 loss 를 만들어내기. (이미 있는 loss들 중 선택할 수 있음.)\n",
        " \n",
        "#Loss함수를 정의 -> criterion : 기준. 어떤 loss를 줄일 것인지에 대해서 명시한다.\n",
        "criterion = torch.nn.MSELoss(size_average=False) \n",
        "# MSELoss는 Mean Squared Error Loss의 줄임말로, \n",
        "# 원본과 예측의 차이의 제곱의 평균을 구해준다는 의미를 가진다.\n",
        "# size_average를 false로 하면 Loss를 발생시키는 것들의 평균으로 나누지 않는다.\n",
        "\n",
        "#Optimize방법을 정의 -> Stochastic Gradient Descent방법을 사용하고, 학습률은 0.01임 \n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=0.01)\n",
        "#이전 글에서는 optimizer 없이 직접 그냥 뺀 값을 적용 해 주었는데, \n",
        "#이번에는 그 과정 대신 optimizer을 사용한다.\n",
        "#model.parameters()를 통해서 \n",
        "#우리가 만든 모델의 파라미터들을 옵티마이저에 전달해주면,\n",
        "#우리가 이전에 gradient를 사용해서 업데이트하던 \n",
        "#w = w - grad * learning rate 식 같은 것을 자동으로 해 준다.\n",
        "#단순히 빼기만 해서 하는게 아닌 SGD(stochastic gradient descent) 라는 \n",
        "#방법을 써서 optimizing을 진행한다. 자세한건 구글링해보자.\n",
        "#lr = 0.01로 learning rate를 정해줄 수 있다.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zdkf5Usg6Fr4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "04c7c726-a01d-47d0-a9ff-c2bb3814c0f5"
      },
      "cell_type": "code",
      "source": [
        "# 500회의 epoch를 수행함\n",
        "for epoch in range(501):\n",
        "    # 우리는 모든 x 데이터를 매트릭스(행렬) 형태로 모델에게 넘겨준다.\n",
        "    y_pred = model(x_data) \n",
        "     \n",
        "    # criterion이라는 함수를 통해서 예측과 정답을 비교하는 평가를 진행한다.\n",
        "    # 이 때, MSE Loss 를 criterion에 넣었기 때문에 그것을 기준으로 진행하게 된다.\n",
        "    loss = criterion(y_pred, y_data) \n",
        " \n",
        "    #100회 epoch마다 1번만 출력한다.\n",
        "    if(epoch%100==0):\n",
        "        print(epoch, loss.data[0])\n",
        "     \n",
        "    #gradient descent 직전에 초기화 해주기.\n",
        "    optimizer.zero_grad() \n",
        " \n",
        "    # 구한 loss로부터 back propagation을 통해 각 변수마다 \n",
        "# loss에 대한 gradient 를 구해주기\n",
        "    loss.backward() \n",
        "     \n",
        "    # step()이란 함수를 실행시키면 우리가 미리 선언할 때 \n",
        "    # 지정해 준 model의 파라미터들이 업데이트 된다.\n",
        "    optimizer.step() \n",
        "    # 이전 글의 기존 for loop을 이용한 방법으로는 데이터를 \n",
        "    # 한번에 하나씩 살펴봐야 해서 효율적이지 못했지만 이제는 한번에 묶어서 계산한다.\n",
        "    # 지금 데이터는 3개라 한번에 봐도 문제가 없지만 몇백만개 이상이 되면 문제가 생긴다.\n",
        "    # SGD를 통해서 업데이트를 진행할 경우에는 mini - batch를 \n",
        "    # 사용하는 기법을 통해 이를 해결한다. 자세한 방법은 구글링 해 보자\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0, tensor(0.0001))\n",
            "(100, tensor(0.0000))\n",
            "(200, tensor(5.7076e-06))\n",
            "(300, tensor(1.3423e-06))\n",
            "(400, tensor(3.1540e-07))\n",
            "(500, tensor(7.4195e-08))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:11: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "V8OeF2wq6UFB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df180252-f18d-41ea-d68e-4b2a93994204"
      },
      "cell_type": "code",
      "source": [
        "hour_var = torch.tensor([[4.0]])\n",
        "print(\"predict (after training)\",4,model.forward(hour_var).data[0][0])\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('predict (after training)', 4, tensor(7.9882))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "dBjMLbHl6deh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d56dc95f-dd3f-4406-d992-ff77dd38bf14"
      },
      "cell_type": "code",
      "source": [
        "model.forward(hour_var).data[0][0]\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.9882)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "MqQOzuoVA58h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb56fc28-dd76-4b4a-c25b-887cb2267d80"
      },
      "cell_type": "code",
      "source": [
        "model.forward(hour_var).data[0][0]"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.9882)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "oD-okLwIBkDy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}